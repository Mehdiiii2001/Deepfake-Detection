# ØªØ´Ø®ÛŒØµ ÙˆÛŒØ¯ÛŒÙˆÙ‡Ø§ÛŒ Deepfake Ø¨Ø§ Ù…Ø¯Ù„ ØªØ±Ú©ÛŒØ¨ÛŒ CNN-Transformer
# Hybrid CNN-Transformer Deepfake Detection

[ğŸ‡®ğŸ‡· Persian](#persian) | [ğŸ‡ºğŸ‡¸ English](#english)

<a name="persian"></a>
## ğŸ‡®ğŸ‡· Persian

Ø§ÛŒÙ† Ù¾Ø±ÙˆÚ˜Ù‡ ÛŒÚ© Ø³ÛŒØ³ØªÙ… Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø¨Ø±Ø§ÛŒ ØªØ´Ø®ÛŒØµ ÙˆÛŒØ¯ÛŒÙˆÙ‡Ø§ÛŒ Ø¬Ø¹Ù„ÛŒ (Deepfake) Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ÛŒÚ© Ù…Ø¯Ù„ ØªØ±Ú©ÛŒØ¨ÛŒ CNN-Transformer Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ú©Ø±Ø¯Ù‡ Ø§Ø³Øª.

### ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø§ØµÙ„ÛŒ

- ØªØ±Ú©ÛŒØ¨ CNN Ùˆ Transformer Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ù‡Ù…Ø²Ù…Ø§Ù† ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ù…Ú©Ø§Ù†ÛŒ Ùˆ Ø²Ù…Ø§Ù†ÛŒ
- Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø§Ø² Ø´Ø¨Ú©Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾Ø§ÛŒÙ‡ Ù…Ø®ØªÙ„Ù (EfficientNet-B0 Ùˆ ResNet50)
- Ø¢Ù…ÙˆØ²Ø´ Ù…ØªØ®Ø§ØµÙ… (Adversarial Training) Ø¨Ø±Ø§ÛŒ Ù…Ù‚Ø§Ø¨Ù„Ù‡ Ø¨Ø§ Deepfakeâ€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡
- Ù…Ú©Ø§Ù†ÛŒØ²Ù…â€ŒÙ‡Ø§ÛŒ ØªÙˆØ¬Ù‡ (Attention) Ù…Ú©Ø§Ù†ÛŒ Ùˆ Ø²Ù…Ø§Ù†ÛŒ
- Ù¾Ø±Ø¯Ø§Ø²Ø´ Ú©Ø§Ø±Ø¢Ù…Ø¯ ÙØ±ÛŒÙ…â€ŒÙ‡Ø§ÛŒ ÙˆÛŒØ¯ÛŒÙˆÛŒÛŒ

### Ù¾ÛŒØ´â€ŒÙ†ÛŒØ§Ø²Ù‡Ø§

```bash
# Ù†ØµØ¨ ÙˆØ§Ø¨Ø³ØªÚ¯ÛŒâ€ŒÙ‡Ø§
pip install -r requirements.txt
```

### Ø³Ø§Ø®ØªØ§Ø± Ù¾Ø±ÙˆÚ˜Ù‡

```
deepfake-detection/
â”œâ”€â”€ deepfake_detector.py     # Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…Ø¯Ù„ Ø§ØµÙ„ÛŒ
â”œâ”€â”€ train_deepfake_detector.py   # Ø§Ø³Ú©Ø±ÛŒÙ¾Øª Ø¢Ù…ÙˆØ²Ø´
â”œâ”€â”€ predict.py              # Ø§Ø³Ú©Ø±ÛŒÙ¾Øª Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ
â”œâ”€â”€ prepare_dataset.py      # Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯ÛŒØªØ§Ø³Øª
â”œâ”€â”€ requirements.txt        # ÙˆØ§Ø¨Ø³ØªÚ¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ù¾Ø±ÙˆÚ˜Ù‡
â””â”€â”€ README.md              # Ù…Ø³ØªÙ†Ø¯Ø§Øª
```

### Ù†Ø­ÙˆÙ‡ Ø§Ø³ØªÙØ§Ø¯Ù‡

#### Û±. Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…Ø­ÛŒØ·
```bash
# Ø§ÛŒØ¬Ø§Ø¯ Ù…Ø­ÛŒØ· Ù…Ø¬Ø§Ø²ÛŒ
python -m venv venv

# ÙØ¹Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ù…Ø­ÛŒØ· Ù…Ø¬Ø§Ø²ÛŒ Ø¯Ø± Windows
.\venv\Scripts\activate
# ÛŒØ§ Ø¯Ø± Linux/Mac
source venv/bin/activate

# Ù†ØµØ¨ ÙˆØ§Ø¨Ø³ØªÚ¯ÛŒâ€ŒÙ‡Ø§
pip install -r requirements.txt
```

#### Û². Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯ÛŒØªØ§Ø³Øª
```bash
python prepare_dataset.py
```

Ø³Ø§Ø®ØªØ§Ø± Ø¯ÛŒØªØ§Ø³Øª Ø¨Ø§ÛŒØ¯ Ø¨Ù‡ ØµÙˆØ±Øª Ø²ÛŒØ± Ø¨Ø§Ø´Ø¯:
```
data/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ real/          # ÙˆÛŒØ¯ÛŒÙˆÙ‡Ø§ÛŒ ÙˆØ§Ù‚Ø¹ÛŒ Ø¨Ø±Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´
â”‚   â””â”€â”€ fake/          # ÙˆÛŒØ¯ÛŒÙˆÙ‡Ø§ÛŒ Ø¬Ø¹Ù„ÛŒ Ø¨Ø±Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´
â””â”€â”€ val/
    â”œâ”€â”€ real/          # ÙˆÛŒØ¯ÛŒÙˆÙ‡Ø§ÛŒ ÙˆØ§Ù‚Ø¹ÛŒ Ø¨Ø±Ø§ÛŒ Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ
    â””â”€â”€ fake/          # ÙˆÛŒØ¯ÛŒÙˆÙ‡Ø§ÛŒ Ø¬Ø¹Ù„ÛŒ Ø¨Ø±Ø§ÛŒ Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ
```

#### Û³. Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„
```bash
python train_deepfake_detector.py \
    --data_dir data \
    --batch_size 8 \
    --num_epochs 50 \
    --backbone efficientnet_b0
```

Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´:
- `--data_dir`: Ù…Ø³ÛŒØ± Ø¯ÛŒØªØ§Ø³Øª
- `--batch_size`: Ø§Ù†Ø¯Ø§Ø²Ù‡ Ø¯Ø³ØªÙ‡ (Ù¾ÛŒØ´â€ŒÙØ±Ø¶: Û¸)
- `--num_epochs`: ØªØ¹Ø¯Ø§Ø¯ Ø¯ÙˆØ±Ù‡â€ŒÙ‡Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´ (Ù¾ÛŒØ´â€ŒÙØ±Ø¶: ÛµÛ°)
- `--lr`: Ù†Ø±Ø® ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ (Ù¾ÛŒØ´â€ŒÙØ±Ø¶: Û°.Û°Û°Û°Û±)
- `--num_frames`: ØªØ¹Ø¯Ø§Ø¯ ÙØ±ÛŒÙ…â€ŒÙ‡Ø§ÛŒ Ù‡Ø± Ú©Ù„ÛŒÙ¾ (Ù¾ÛŒØ´â€ŒÙØ±Ø¶: Û±Û¶)
- `--backbone`: Ù…Ø¹Ù…Ø§Ø±ÛŒ CNN Ù¾Ø§ÛŒÙ‡ (Ú¯Ø²ÛŒÙ†Ù‡â€ŒÙ‡Ø§: efficientnet_b0ØŒ resnet50)
- `--checkpoint_dir`: Ù…Ø³ÛŒØ± Ø°Ø®ÛŒØ±Ù‡ Ù…Ø¯Ù„ (Ù¾ÛŒØ´â€ŒÙØ±Ø¶: checkpoints)
- `--no_adversarial`: ØºÛŒØ±ÙØ¹Ø§Ù„ Ú©Ø±Ø¯Ù† Ø¢Ù…ÙˆØ²Ø´ Ù…ØªØ®Ø§ØµÙ…

---

<a name="english"></a>
## ğŸ‡ºğŸ‡¸ English

This project implements an intelligent system for detecting deepfake videos using a hybrid CNN-Transformer model.

### Key Features

- Combined CNN and Transformer for simultaneous spatial-temporal analysis
- Support for multiple backbone networks (EfficientNet-B0 and ResNet50)
- Adversarial training to combat advanced deepfakes
- Spatial and temporal attention mechanisms
- Efficient video frame processing

### Prerequisites

```bash
# Install dependencies
pip install -r requirements.txt
```

### Project Structure

```
deepfake-detection/
â”œâ”€â”€ deepfake_detector.py     # Core model implementation
â”œâ”€â”€ train_deepfake_detector.py   # Training script
â”œâ”€â”€ predict.py              # Prediction script
â”œâ”€â”€ prepare_dataset.py      # Dataset preparation
â”œâ”€â”€ requirements.txt        # Project dependencies
â””â”€â”€ README.md              # Documentation
```

### Usage

#### 1. Environment Setup
```bash
# Create virtual environment
python -m venv venv

# Activate virtual environment on Windows
.\venv\Scripts\activate
# or on Linux/Mac
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

#### 2. Dataset Preparation
```bash
python prepare_dataset.py
```

The dataset should be structured as follows:
```
data/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ real/          # Real videos for training
â”‚   â””â”€â”€ fake/          # Deepfake videos for training
â””â”€â”€ val/
    â”œâ”€â”€ real/          # Real videos for validation
    â””â”€â”€ fake/          # Deepfake videos for validation
```

#### 3. Model Training
```bash
python train_deepfake_detector.py \
    --data_dir data \
    --batch_size 8 \
    --num_epochs 50 \
    --backbone efficientnet_b0
```

Training parameters:
- `--data_dir`: Dataset path
- `--batch_size`: Batch size (default: 8)
- `--num_epochs`: Number of training epochs (default: 50)
- `--lr`: Learning rate (default: 0.0001)
- `--num_frames`: Number of frames per clip (default: 16)
- `--backbone`: CNN backbone architecture (options: efficientnet_b0, resnet50)
- `--checkpoint_dir`: Model save path (default: checkpoints)
- `--no_adversarial`: Disable adversarial training

#### 4. Prediction
```bash
python predict.py \
    --input path/to/video.mp4 \
    --model_path checkpoints/best_model.pth
```

Prediction parameters:
- `--input`: Input video path
- `--model_path`: Trained model path
- `--num_frames`: Number of frames to analyze
- `--backbone`: CNN backbone architecture

### Model Architecture Details

#### 1. Spatial Feature Extractor (CNN)
- Uses EfficientNet-B0 or ResNet50
- Spatial attention mechanism
- High-level feature extraction from frames

#### 2. Temporal Analyzer (Transformer)
- Positional encoding for temporal information
- Multi-head self-attention mechanism
- Temporal inconsistency detection

#### 3. Fusion Mechanism
- Spatial and temporal feature fusion
- Fully connected layers with dropout
- Final sigmoid output

### Addressing Challenges

#### 1. Advanced Deepfakes
- PGD-based adversarial training
- Support for multiple CNN architectures
- Attention mechanisms for detail detection

#### 2. Dataset Bias
- Balanced data split (80/20)
- Data augmentation with transformations
- Independent validation

#### 3. Computational Efficiency
- Smart frame sampling
- Batch processing
- GPU memory optimization
- Learning rate scheduling

### Results and Output

For each input video, the system provides:
- Classification (REAL/FAKE)
- Confidence percentage
- Annotated result image

### Contributing

Your contributions to improve the project are valuable. Please:
1. Fork the project
2. Create a new branch
3. Make your changes
4. Submit a Pull Request

### License

This project is licensed under the MIT License.

### Support

For issues or suggestions, please create an Issue.